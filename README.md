
# Basic Text Preprocessing and Tokenization

assignment1.py performs text preprocessing and tokenization, including:

- Text cleaning
- Sentence and words tokenization
- Top 10 most common words with count

# Requirements and external libraries

- Python 3.7+
- `NLTK (Natural Language Toolkit)`: For natural language processing and word frequency analysis.
- `TextBlob`: For tokenizing text into words
- `Tabulate`: For formatting the results into a table

# Installation
- Clone the repository
- Install required dependencies
```python
    pip install nltk textblob tabulate
```

# Usage

- Place your input text file in the project directory
- Update the input_file path in the main() function
- Run the script:
``` python
    python assignment1.py
```
